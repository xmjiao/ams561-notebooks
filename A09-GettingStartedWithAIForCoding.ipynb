{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20b66378-6a90-461a-b5a5-f185dfc98e8e",
   "metadata": {},
   "source": [
    "# Getting started with AI coding assistants\n",
    "\n",
    "* **Basic introduction to modern \"AI\"**\n",
    "  * **There's (mostly) no \"I\" in current \"AI\"**: We're primarily dealing with sophisticated pattern-matching and statistical models, *not* true artificial general intelligence (AGI) yet.  They are trained on vast amounts of data and learn to predict the most likely next word/code snippet/response.\n",
    "  * **Basic technologies and concepts**\n",
    "    * **Large Language Models (LLMs)**: These are the foundation of most modern AI assistants.  They are neural networks with *billions* (or even trillions) of parameters, trained on massive text (and sometimes code) datasets.  Examples include the GPT series (from OpenAI), Gemini (from Google), Claude (from Anthropic), and DeepSeek (from China).\n",
    "    * **Transformers**:  A specific neural network architecture that is particularly effective for LLMs.  The key innovation is the \"attention mechanism,\" which allows the model to weigh the importance of different parts of the input when generating output.\n",
    "    * **Generative AI**:  A broader category encompassing LLMs and other models (like image generators - DALL-E, Midjourney, Stable Diffusion) that can create new content, rather than just analyzing existing data.\n",
    "  * **How to get good results**\n",
    "    * **Prompt engineering**:  The art and science of crafting effective input prompts to guide the AI towards the desired output.  This is *crucial* for good results.\n",
    "  * **Ethical concerns**\n",
    "    * **AI in general in [higher education](https://www.insidehighered.com/sites/default/files/2023-10/Benefits%2C%20Challenges%2C%20and%20Sample%20Use%20Cases%20of%20AI%20in%20Higher%20Education.pdf)** (and beyond) - This is a rapidly evolving area with many considerations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893472c5-a92c-4cdb-b1a2-3d8cb964f7b9",
   "metadata": {},
   "source": [
    "## Prompt engineering\n",
    "\n",
    "This is a set of techniques for guiding (constraining) the AI tool to give you what you want.  It's more of an art than a precise science, and best practices are still emerging.\n",
    "\n",
    "* **Key Principles (Not Just Asking the Models):** While asking the models for advice is a starting point, it's often *not* the best way to learn advanced techniques.  The models are trained on a snapshot of the internet, and prompt engineering is evolving faster than that snapshot.\n",
    "    * **Specificity:** Be as clear and unambiguous as possible about what you want.  Instead of \"Write a function,\" say \"Write a Python function named `calculate_average` that takes a list of numbers as input and returns their average.  Handle the case where the list is empty by returning 0.\"\n",
    "    * **Context:** Provide relevant background information.  For example, if you're working with a specific library, mention it: \"Using the `pandas` library in Python, ...\"\n",
    "    * **Constraints:**  Specify limitations or requirements.  \"The function should be no more than 20 lines long.\"  \"The output should be in JSON format.\"\n",
    "    * **Persona:**  Sometimes, it helps to tell the AI to act as a specific role: \"You are a senior Python developer.  Write a function that...\"\n",
    "    * **Few-Shot Examples:** Provide examples of the input and desired output. This is *very* effective for many tasks.  Example:  \"Here's an example of the input and output:\\n\\nInput: `[1, 2, 3, 4, 5]`\\nOutput: `3.0`\"\n",
    "    * **Step-by-Step Instructions:** Break down complex tasks into smaller, sequential steps. \"First, read the data from the CSV file.  Then, clean the data by removing any rows with missing values.  Finally, calculate the average of the 'price' column.\"\n",
    "    * **Iterative Refinement:** Don't expect the first response to be perfect.  Refine your prompt based on the output, providing feedback and additional constraints.\n",
    "    * **Temperature and Top-p:** These are parameters that control the randomness of the model's output.  Lower temperature (closer to 0) makes the output more deterministic and focused.  Higher temperature (closer to 1) makes it more creative and varied.  Top-p sampling is another way to control randomness.  You usually access these through an API, not directly in a chat interface.\n",
    "    * **Chain-of-Thought (CoT) Prompting:**  Encourage the model to \"think step by step\" before providing the final answer.  This often improves reasoning and accuracy, especially for complex problems.  Example: \"Write a function to reverse a linked list.  Explain your reasoning step-by-step before showing the code.\"\n",
    "    * **Chain of Verification (CoV):** An emerging approach. The goal is to avoid having the AI simply produce an output, but also check its results.\n",
    "\n",
    "* **Resources:**\n",
    "    *   [Latest Prompt Engineering Techniques](https://www.forbes.com/sites/lanceeliot/2023/09/23/latest-prompt-engineering-technique-chain-of-verification-does-a-sleek-job-of-keeping-generative-ai-honest-and-upright/?sh=22c2a0be46d7) (Forbes article - still relevant, but CoV is becoming more integrated)\n",
    "    *   [Prompt Engineering Guide](https://www.promptingguide.ai/) (Excellent, comprehensive, and frequently updated resource)\n",
    "    *   [OpenAI Cookbook](https://github.com/openai/openai-cookbook) (Examples and techniques, primarily focused on the OpenAI API, but many principles apply generally)\n",
    "    *   [Learn Prompting](https://learnprompting.org/) (Another good, general resource)\n",
    "\n",
    "* **Iterative Improvement Examples:**\n",
    "\n",
    "    *   **Iteration 1:** \"Write a Python function to convert a JSON file to XML.\"\n",
    "    *   **Iteration 2:** \"Write a Python function to convert a JSON file to XML.  Include a docstring and comments.  Also, generate example JSON input and the corresponding XML output.\" (Adding few-shot learning)\n",
    "    *   **Iteration 3:** \"Write a Python function named `json_to_xml` in a module named `converter.py`.  The function should take two arguments: `input_json_file` (the path to the input JSON file) and `output_xml_file` (the path to the output XML file).  Use Python's built-in `json` and `xml.etree.ElementTree` modules.  Handle potential errors gracefully (e.g., file not found, invalid JSON). Include a docstring for the function and comments explaining each step. Add a `if __name__ == '__main__':` block to `converter.py` that demonstrates how to use the function with example command-line arguments.  Here's an example of the JSON input and desired XML output: ...\" (Much more specific, includes error handling, and specifies modules)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be1aad9",
   "metadata": {},
   "source": [
    "## Using AI Coding Assistants (ChatGPT, Gemini, Claude, Copilot, etc.)\n",
    "\n",
    "This section provides a more general overview of how to use various AI coding assistants. While the specific interfaces and features differ, the underlying principles are similar.\n",
    "\n",
    "**Capabilities (Common Across Many Assistants):**\n",
    "\n",
    "*   **Code Generation:**  Generating code snippets, functions, classes, or even entire programs based on natural language descriptions.\n",
    "*   **Code Completion:**  Suggesting code completions as you type (like a very smart autocomplete).\n",
    "*   **Code Explanation:**  Explaining what a piece of code does in plain English.\n",
    "*   **Debugging:**  Identifying potential bugs and suggesting fixes.\n",
    "*   **Refactoring:**  Suggesting improvements to code structure and style.\n",
    "*   **Documentation Generation:**  Writing docstrings, comments, and user documentation.\n",
    "*   **Test Case Generation:**  Creating unit tests and other test cases.\n",
    "*   **Translation:**  Converting code from one programming language to another.\n",
    "*   **Question Answering:**  Answering general programming questions and providing information about specific APIs, libraries, and frameworks.\n",
    "*   **Web Browsing (for some):**  Some assistants (e.g., Bing Chat/Copilot, some Gemini modes, Perplexity) can access the web to retrieve up-to-date information.\n",
    "\n",
    "**Specific Tools and Platforms:**\n",
    "\n",
    "*   **ChatGPT:**  A web-based chat interface.  Good for general-purpose questions and code generation.  Different versions (GPT-3.5, GPT-4, GPT-4o) have different capabilities.\n",
    "*   **Gemini:**  Google's family of models.  Gemini Pro is available through a web interface and API. Gemini 2.0 Pro (currently in preview) has a *massive* context window.\n",
    "* **Claude 3.5 (Sonnet, Haiku, Opus):** Anthropic models are focused on AI safety. Sonnet is the model available through a free web interface.\n",
    "*   **GitHub Copilot:**  An AI pair programmer that integrates directly into code editors like VS Code, Visual Studio, Neovim, and JetBrains IDEs.  It provides real-time code suggestions, autocompletion, and can generate code from comments.\n",
    "*   **Copilot Chat:**  A chat interface within VS Code (and other IDEs) that allows you to interact with Copilot in a conversational way.\n",
    "*   **Amazon CodeWhisperer:**  Similar to Copilot, but integrated with AWS services.\n",
    "*   **Tabnine:**  Another AI code completion tool.\n",
    "*   **Replit Ghostwriter:**  AI assistance integrated into the Replit online IDE.\n",
    "*   **Perplexity:** Focuses on providing verifiable answers with sources. It is often used to get current status and capabilities of models. It uses several different models as its backend (including DeepSeek R1).\n",
    "* **Phind:** Another AI search engine, often with strong performance on technical questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8933d31",
   "metadata": {},
   "source": [
    "### Understanding Context Windows\n",
    "\n",
    "The *context window* is the amount of text (measured in tokens) that the AI model can \"see\" at once. This includes:\n",
    "\n",
    "*   **Your Prompt:** The text you type to instruct the AI.\n",
    "*   **The Conversation History:**  Previous turns in a chat-based interaction.\n",
    "*   **Code in the Current File (for IDE integrations):** Copilot and similar tools can often \"see\" the code in the current file you're editing.\n",
    "*   **Code in *Open* Files (for some IDE integrations):**  Some tools can access code in other *open* files in your editor. This is *very* important.\n",
    "*   **Retrieved Documents (for RAG):**  If the AI uses Retrieval-Augmented Generation (RAG), it can fetch relevant documents from a knowledge base and include them in the context.\n",
    "\n",
    "**Why Context Windows Matter:**\n",
    "\n",
    "*   **Limited Memory:**  If your prompt + code + conversation history exceeds the context window, the AI will \"forget\" earlier parts of the conversation or code. Older prompts within the same session *may* have diminishing effects.\n",
    "*   **Code Generation Quality:**  For code generation, a larger context window allows the AI to understand more of your project's structure and dependencies, leading to more accurate and relevant code.\n",
    "*   **Long Documents:**  For tasks like summarizing long documents or answering questions about them, a large context window is essential.\n",
    "\n",
    "**Current Models (and approximate context windows - *check official documentation!*):**\n",
    "\n",
    "*   **GPT-4o:** ~128,000 tokens. Older versions of GPT-4 and GPT-3.5 Turbo had ~8,000--32,000 tokens (some versions have 128k, but access is limited) and ~4,000 - 16,000 tokens (depending on the specific version), respectively,\n",
    "*   **Claude 3 Sonnet/Opus/Haiku:** ~200,000 tokens (Anthropic is known for large context windows).\n",
    "*   **Gemini 2.0 Pro:**  Up to 2 *million* tokens (in preview).  This is a *major* development. Older versions of Gemini 1.5 and 1.0 Pro had up to 1 *million* and ~32,000 tokens, respectively.\n",
    "*    **Perplexity**: Varies as it acts as an interface.\n",
    "\n",
    "**Strategies for Working with Context Windows:**\n",
    "\n",
    "*   **Be Concise:** Write clear and concise prompts.\n",
    "*   **Break Down Tasks:**  Divide large tasks into smaller, more manageable subtasks.\n",
    "*   **Summarize:**  If you have a long conversation, periodically ask the AI to summarize the key points.\n",
    "*   **Use Comments:**  Provide helpful comments in your code to guide the AI.\n",
    "*   **Open Relevant Files:**  In IDE integrations, make sure any relevant files are open so the AI can access them.\n",
    "*   **Use RAG (if available):**  If you're working with a large codebase or knowledge base, use a tool that supports RAG."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698bdc6a",
   "metadata": {},
   "source": [
    "### Understanding Other Limitations\n",
    "\n",
    "* **Lack of State:**  In ChatGPT, information is *not* retained across different sessions.  Each new session starts fresh. Google Gemini, however, retains information across different sessions, which can cause confusion.\n",
    "* **Inconsistent Responses:**  You might get different answers to the same prompt, even within the same session.  This is due to the probabilistic nature of the models.\n",
    "* **Hallucinations:** LLMs can confidently generate incorrect or nonsensical information.  This is often called \"hallucination.\" This used to be a very serious problem but it has got significantly better recently. However, *always* verify the output.\n",
    "* **Lack of Real-World Understanding:** LLMs don't \"understand\" the world in the way humans do, such as the need of your applications, unless you tell it explicitly.  They are pattern-matching machines.  They can be fooled by adversarial prompts or unexpected inputs.\n",
    "* **Data Cutoff:**  Most models have a knowledge cutoff date.  They won't know about events that happened after that date unless you provide the information in the prompt.  (Models with web browsing capabilities, which is support by most venders for some models, can mitigate this).\n",
    "* **Mathematical Reasoning Limits:** While LLMs are getting better at math, they are not reliable calculators.  For complex calculations, use a dedicated tool or ask LLMs to generate code for you.\n",
    "* **Security Risks:**  Be *very* careful about including sensitive information (API keys, passwords, personal data) in prompts.  Consider using environment variables or dedicated secrets management tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94c3604",
   "metadata": {},
   "source": [
    "### Potential Pitfalls:\n",
    "\n",
    "*   **Misinterpretation:** Especially for poorly written or ambiguous prompts.  The model might misunderstand your intent.\n",
    "*   **Over-reliance:** LLMs may produce inaccurate, incomplete, and even harmful output if not verified or monitored properly. *Never* blindly trust the generated code or information.\n",
    "*   **Exposure to Biases:** LLMs can exhibit biases present in their training data (e.g., in comments, variable names, or code examples).  This can lead to biased or unfair software.\n",
    "* **Copyright and Licensing Issues**: The output may be close, verbatim or derivative of copyrighted code or documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52b2789",
   "metadata": {},
   "source": [
    "### Importance of Verification:\n",
    "\n",
    "Ensuring correctness and completeness is *crucial* yet intricate in the development process.  You *must* treat the AI as an assistant, not an oracle.\n",
    "\n",
    "**Chain of Verification (CoV):**\n",
    "\n",
    "An emerging technique aims to enhance reliability and accuracy. CoV is designed to make the LLM verify its own output through a series of steps. It's becoming more common for models to have this built-in. However, users may still need to structure their prompts to encourage the process.\n",
    "Process of CoV:\n",
    "1.  **Draft Initial Response:** Formulate a preliminary response based on the initial analysis.\n",
    "2.  **Plan Verification Questions:** Develop questions to verify the accuracy and completeness of the initial response (potentially with help from the AI).\n",
    "3.  **Answer Questions Independently:** Evaluate the verification questions without relying on the initial response.\n",
    "4.  **Generate Final Verified Response:** Integrate the insights gained from the verification questions to produce a refined, verified response.\n",
    "\n",
    "**Other Verification Strategies:**\n",
    "\n",
    "*   **Unit Tests:**  Write comprehensive unit tests to check the functionality of generated code.\n",
    "*   **Code Reviews:**  Have another developer review the code, even if it was generated by an AI.\n",
    "*   **Static Analysis Tools:**  Use linters and static analyzers to catch potential errors and style issues.\n",
    "*   **Manual Review:** Carefully read and understand the generated code *before* using it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f645d6",
   "metadata": {},
   "source": [
    "## Ethical concerns of using AI in software development\n",
    "\n",
    "The use of AI in software development raises several ethical concerns. It's important to be aware of these issues and to use AI responsibly.\n",
    "\n",
    "Here's a breakdown of the ethical issues, along with considerations for responsible use (much of this is based on answers from Gemini 2.0 Pro):\n",
    "\n",
    "1.  **Bias and Discrimination**\n",
    "\n",
    "    *   **The Issue:** AI models are trained on massive datasets, which often reflect existing societal biases.  If the training data contains biased code, comments, or documentation, the AI may perpetuate and even amplify these biases in the software it helps create. This can lead to unfair or discriminatory outcomes.  Examples:\n",
    "        *   A code completion tool might suggest variable names that reflect gender stereotypes.\n",
    "        *   An AI-powered code review tool might be more likely to flag code written by certain demographic groups.\n",
    "        *   An AI system used for code generation might generate code containing harmful comments.\n",
    "    *   **Mitigation:**\n",
    "        *   **Data Awareness:** Carefully examine training datasets for potential biases. Use techniques to actively balance and de-bias data when possible.\n",
    "        *   **Algorithmic Fairness:** Utilize algorithms and techniques designed to promote fairness and mitigate bias.  This is an active area of research.\n",
    "        *   **Continuous Monitoring:** Implement systems to monitor AI-powered software for biased outcomes.  Adjust models as needed.\n",
    "        *   **Diverse Development Teams:**  Having diverse teams involved in the development and evaluation of AI systems can help identify and address potential biases.\n",
    "\n",
    "2.  **Lack of Transparency and Explainability**\n",
    "\n",
    "    *   **The Issue:**  Complex AI models (especially deep learning models) can be \"black boxes.\" It's difficult to understand *why* they made a particular decision or generated a specific piece of code. This lack of transparency makes it hard to audit results, identify errors, and build trust.\n",
    "    *   **Mitigation:**\n",
    "        *   **Explainable AI (XAI):**  Explore and utilize XAI techniques to make AI models more understandable.  This is a rapidly developing field.\n",
    "        *   **Simpler Models:** When possible, choose simpler, more interpretable models over complex ones, especially when explainability is critical.\n",
    "        *   **Documentation:**  Even if the model itself is a black box, document the *process* used to train and deploy it, including data sources, preprocessing steps, and evaluation metrics.\n",
    "\n",
    "3.  **Accountability and Responsibility**\n",
    "\n",
    "    *   **The Issue:** When AI-generated code contains errors, introduces security vulnerabilities, or leads to unintended consequences, who is responsible? The developers? The data scientists? The company deploying the AI?  The legal and ethical frameworks are still catching up.\n",
    "    *   **Mitigation:**\n",
    "        *   **Clearly Defined Roles:** Establish clear guidelines for responsibility at each stage of AI development and deployment.\n",
    "        *   **Regulation and Standards:** Advocate for and adhere to industry standards and regulations related to AI development and use.\n",
    "        *   **Auditable Trails:** Maintain detailed records of model development, training data, and implementation decisions.\n",
    "        *   **Human Oversight:**  AI should be used as a tool to *assist* developers, not to replace them entirely.  Human review and validation are essential.\n",
    "\n",
    "4.  **Job Displacement and Economic Impacts**\n",
    "\n",
    "    *   **The Issue:** AI-powered tools can automate some software development tasks, potentially leading to job displacement.\n",
    "    *   **Mitigation:**\n",
    "        *   **Reskilling and Upskilling:** Invest in programs to train and retrain workers in new skills that are relevant in an AI-driven world.\n",
    "        *   **Focus on New Opportunities:**  AI can also create new job opportunities in areas like AI development, maintenance, and oversight.\n",
    "        *   **Social Safety Nets:**  Consider policies to mitigate the potential negative impacts of job displacement.\n",
    "\n",
    "5.  **Privacy and Security**\n",
    "\n",
    "    *   **The Issue:** AI models often require large amounts of data, which may include sensitive code or proprietary information. Security breaches or misuse of this data could have serious consequences.\n",
    "    *   **Mitigation:**\n",
    "        *   **Privacy by Design:**  Build privacy considerations into the AI development process from the start.\n",
    "        *   **Data Minimization:** Collect and use only the data that is strictly necessary.\n",
    "        *   **Data Anonymization and Pseudonymization:**  Anonymize or pseudonymize data whenever possible to protect the privacy of individuals and organizations.\n",
    "        *   **Robust Security Measures:** Implement strong security protocols to protect data from unauthorized access and breaches.\n",
    "        *   **Secure Coding Practices:** Train developers on secure coding practices to minimize vulnerabilities in AI-powered software.\n",
    "\n",
    "6.  **Intellectual Property and Copyright**\n",
    "\n",
    "    *   **The Issue:** AI models are trained on existing code, which may be subject to copyright or other intellectual property restrictions.  It's not always clear whether AI-generated code infringes on these rights.  There are also questions about who owns the copyright to AI-generated code.\n",
    "    * **Mitigation:**\n",
    "        *   **Understand Licensing:** Be aware of the licenses of the code used to train AI models.\n",
    "        *   **Use Permissively Licensed Data:**  When possible, use training data that is permissively licensed (e.g., MIT, Apache 2.0).\n",
    "        *   **Code Attribution:**  Develop tools and techniques to track the provenance of AI-generated code and attribute it appropriately.\n",
    "        *   **Legal Guidance:** Consult with legal experts on intellectual property issues related to AI-generated code.\n",
    "        *   **Avoid Training on Proprietary Code Without Permission:** This is a critical ethical and legal point.\n",
    "\n",
    "7. **De-skilling and Over-Reliance**\n",
    "    * **The issue**: With dependence on code assistance, developers may find their fundamental skills diminish.\n",
    "    * **Mitigation**\n",
    "        * Establish policies and guidelines for how and when these tools should be used.\n",
    "        * Integrate tools thoughtfully into educational curricula, focusing on how to use them effectively and critically.\n",
    "        * Ensure developers understand when *not* to use the tools, especially for foundational learning.\n",
    "        * Create learning environments that balance hands-on coding exercises with AI-assisted projects.\n",
    "\n",
    "8. **Code Quality and Long-Term Maintainability**\n",
    "\n",
    "    *   **The Issue:**  While AI can generate code quickly, the long-term quality and maintainability of that code are not guaranteed.  AI-generated code might be difficult to understand, debug, or modify.  There's a risk of accumulating \"technical debt\" if AI-generated code is not carefully reviewed and refactored. There is concern that a growing global codebase created by assistance tools could lead to stagnation or decline in overall quality.\n",
    "    *   **Mitigation:**\n",
    "        *   **Code Reviews:**  Thorough code reviews are *essential*.\n",
    "        *   **Refactoring:**  Treat AI-generated code as a first draft that may need significant refactoring.\n",
    "        *   **Testing:**  Comprehensive testing (unit tests, integration tests, etc.) is crucial.\n",
    "        *   **Style Guides and Standards:**  Enforce coding style guides and standards to ensure consistency and maintainability.\n",
    "\n",
    "**Important Considerations:**\n",
    "\n",
    "*   **Ongoing Ethical Development:** Ethical considerations should be integrated into the *entire* software development lifecycle, from design to deployment and maintenance. This is not a one-time checklist.\n",
    "*   **Collaboration:**  Addressing these ethical challenges requires collaboration between developers, researchers, policymakers, and the broader community.\n",
    "*   **Education and Training:** Developers need to be educated about the ethical implications of AI and trained in responsible AI development practices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab066fb9",
   "metadata": {},
   "source": [
    "### Additional Considerations\n",
    "\n",
    "* **Missing attribution** and potential plagiarism in an academic setting.\n",
    "* **Licensing**\n",
    "    * Ignoring licenses in training data.\n",
    "    * Can one license generated code?\n",
    "* **What can human developers do that AI cannot do?**\n",
    "    * Understanding the needs of your applications.\n",
    "    * Integration of individual pieces into a larger project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c2a4f0-d71a-4782-a3bb-c7c141ecb900",
   "metadata": {},
   "source": [
    "## Test questions (Interactive)\n",
    "\n",
    "We will try to get these answered interactively during class...\n",
    "\n",
    "0.  How does XXX work? (Specify XXX - e.g., \"How does the transformer architecture work?\", \"How does GitHub Copilot access my code?\")\n",
    "1.  What should I do to get better results from you?\n",
    "2.  Please summarize your capabilities.\n",
    "3.  How can you assist with writing software?\n",
    "4.  Please write a Python program to plot a golden-ratio spiral using matplotlib.\n",
    "5.  Please explain this program\n",
    "6.  Please write a Python function that takes a floating-point argument x and computes the exponential of the square root of that number.\n",
    "7.  Please also implement a function that computes the derivative of the previous function with respect to its argument x.\n",
    "8.  Please test this function by using central difference to estimate the derivative of the original function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012af82d",
   "metadata": {},
   "source": [
    "\n",
    "**Using Copilot in VS Code (Example - Many principles apply to other tools):**\n",
    "\n",
    "1.  **Installation:**  Install the GitHub Copilot extension from the VS Code Marketplace. You'll need a GitHub account and a Copilot subscription (there may be free trials or student/academic options).\n",
    "2.  **Authentication:**  You'll need to authenticate with your GitHub account.\n",
    "3.  **Automatic Suggestions:**  As you type code, Copilot will automatically suggest completions.  These suggestions appear in grayed-out text.  You can accept a suggestion by pressing `Tab`.\n",
    "4.  **Inline Chat (Copilot Chat):**\n",
    "    *   Open the chat panel (View -> Open View... -> Copilot Chat).\n",
    "    *   Type your questions or requests in natural language.\n",
    "    *   Use `@workspace` to let it know you're talking about your whole project.\n",
    "    *   Use `@vscode` to ask questions about how to use VSCode.\n",
    "    *   Use `/` for specific commands. For example:\n",
    "        *   `/doc`: Generate documentation for the selected code.\n",
    "        *   `/explain`: Explain the selected code.\n",
    "        *   `/fix`: Suggest a fix for a problem in the selected code.\n",
    "        *   `/tests`: Generate unit tests for the selected code.\n",
    "        *   `/new`: Create a new file/project.\n",
    "        *   `/help`: Get a list of commands.\n",
    "5.  **Prompts:**\n",
    "    *   Be as specific as possible.\n",
    "    *   Use comments to guide Copilot. For example, you can write a comment like `// Function to calculate the factorial of a number` and Copilot will often generate the entire function.\n",
    "    *   Iterate and refine your prompts.\n",
    "6.  **History:**  Copilot Chat keeps a history of your conversations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b8c07f-b9ce-4b2a-b046-e88747c0eab4",
   "metadata": {},
   "source": [
    "## Github (Microsoft) Copilot in VSCode\n",
    "\n",
    "1. Getting it set up (install extension, authenticate if needed)\n",
    "2. Using it inside Jupyter notebook\n",
    "   * prompts\n",
    "   * slash commands\n",
    "   * history\n",
    "   * automatic suggestions\n",
    "3. Chatting inside VSCode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a33c67-2e2e-4aa2-9626-93111186c714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def golden_spiral(num_points=1000):\n",
    "    \"\"\"\n",
    "    Generate points for a golden ratio spiral.\n",
    "\n",
    "    Parameters:\n",
    "    - num_points: The number of points to generate for the spiral.\n",
    "\n",
    "    Returns:\n",
    "    - (x, y): Tuple of arrays representing the x and y coordinates of the spiral.\n",
    "    \"\"\"\n",
    "    golden_ratio = (1 + np.sqrt(5)) / 2  # Approximate value of the golden ratio\n",
    "    theta = np.linspace(0, 4 * np.pi, num_points)  # Angle array\n",
    "    # The radius grows exponentially with the angle\n",
    "    radius = np.power(golden_ratio, theta / (2 * np.pi))\n",
    "\n",
    "    # Convert polar coordinates to Cartesian coordinates\n",
    "    x = radius * np.cos(theta)\n",
    "    y = radius * np.sin(theta)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "# Plotting the golden-ratio spiral\n",
    "x, y = golden_spiral(num_points=1000)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(x, y)\n",
    "plt.title(\"Golden-Ratio Spiral\")\n",
    "plt.axis(\"equal\")  # Ensure the aspect ratio is equal to make the spiral look correct\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
