{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning: Classification & Clustering\n",
    "\n",
    "This notebook introduces fundamental concepts in machine learning, focusing on two common tasks: classification and clustering. We will explore how to implement and evaluate various algorithms for these tasks using the popular Python library Scikit-learn. We will primarily use the well-known Iris dataset to illustrate these techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "from sklearn import cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed so that we get the same random numbers\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check version of scikit-learn\n",
    "import sklearn\n",
    "\n",
    "print(\"The scikit-learn version is {}.\".format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "Recall that we already saw in C03 an example of classification where we used a logistic regression to classify Iris flower samples from sepal and petal widths and lengths. Let's consider this data again but now we will consider all 3 species.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load built-in data in the Scikit-Learn library\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bunch is a dictionary-like object. Some useful attributes are:\n",
    "\n",
    "- `data`: the data to learn\n",
    "- `target`: the classification labels\n",
    "- `target_names`: the meaning of the labels\n",
    "- `feature_names`: the meaning of features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data: Training and Testing Sets\n",
    "\n",
    "Before training a model, we need to split our dataset. We'll use a portion for training the model (the *training set*) and reserve the rest for evaluating its performance on unseen data (the *testing set*). This helps us understand how well the model generalizes to new examples. We'll use 70% for training and 30% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into a training part(70%) and a testing part (30%)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    iris.data, iris.target, train_size=0.7, random_state=123 # uncomment to get the same random numbers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First step: create a classifier instance\n",
    "classifier = linear_model.LogisticRegression(solver=\"lbfgs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the 'fit' method to train the classifier\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the class for the samples in the testing datasets\n",
    "#    (so that we can compare the predictions with the actual values)\n",
    "y_test_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sklearn.metrics.classification_report` function returns a text report showing the main classification metrics (see detail [here](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html#sklearn.metrics.precision_recall_fscore_support) )\n",
    "\n",
    "Also:\n",
    "\n",
    "- [precision and recall](https://en.wikipedia.org/wiki/Precision_and_recall)\n",
    "- [F1 score](https://en.wikipedia.org/wiki/F1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the _confusion matrix_ $C$ where $C_{ij}$ is the number of samples of category $i$ that were categorized as _j_. That is, the diagonal elements corresponds to the number of correctly classified samples for each category, and the off-diagonal elements are the number of incorrectly classified samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test, y_test_pred)\n",
    "## NOTE1:  the numbers depend on the random seed\n",
    "## NOTE2:  the sum of each row is the total number of samples for the corresponding category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count unique value in y_test\n",
    "np.bincount(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also plot the confusion matrix\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(classifier, y_test, y_test_pred):\n",
    "    cm = metrics.confusion_matrix(y_test, y_test_pred, labels=classifier.classes_)\n",
    "    disp = metrics.ConfusionMatrixDisplay(\n",
    "        confusion_matrix=cm, display_labels=classifier.classes_\n",
    "    )\n",
    "    disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(classifier, y_test, y_test_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have just used a logistic regression model as a classifier. Other popular classifiers are\n",
    "\n",
    "- decision trees ([detail](https://en.wikipedia.org/wiki/Decision_tree_learning))\n",
    "- nearest neighbor methods ([detail](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) and [overview](https://www.datacamp.com/community/tutorials/k-nearest-neighbor-classification-scikit-learn))\n",
    "- support-vector machine (SVM) ([detail](https://en.wikipedia.org/wiki/Support_vector_machine))\n",
    "- Random Forest method ([detail](https://en.wikipedia.org/wiki/Random_forest) and [detail](https://www.datacamp.com/tutorial/random-forests-classifier-python))\n",
    "\n",
    "See a [flowchart](https://scikit-learn.org/stable/tutorial/machine_learning_map/) of a rough guide on how to choose an estimator and detailed [comparison](https://www.dataschool.io/comparing-supervised-learning-algorithms/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a decision tree as classifier\n",
    "classifier = tree.DecisionTreeClassifier()  # set `random_state=123` to get the same random numbers\n",
    "classifier.fit(X_train, y_train)\n",
    "y_test_pred = classifier.predict(X_test)\n",
    "metrics.confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the decision tree\n",
    "tree.plot_tree(classifier)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the tree. In each box we have a decision\n",
    "\n",
    "- `Parameter <= value` --- tells you the feature and threshold used for splitting data at this node. Samples satisfying the condition go left, others go right.\n",
    "- `Gini` score --- Measures node impurity ($g = 1 - \\sum_c p_c^2$, where $p_c$ is the fraction of samples of class c at the node). A Gini score of 0 means all samples belong to one class. The algorithm chooses splits that maximize the decrease in impurity.\n",
    "- `Samples` --- is the number of training samples reaching that node.\n",
    "- `Value` --- shows the distribution of training samples among the classes at that node (e.g., `[35, 34, 36]` means 35 samples of class 0, 34 of class 1, and 36 of class 2 reached this node). The majority class here often determines the prediction for samples ending up in this node if it's a leaf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the nearest neighbor classifier\n",
    "classifier = neighbors.KNeighborsClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_test_pred = classifier.predict(X_test)\n",
    "metrics.confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default number of neighbors is 5, but this is another example of a hyper parameter. We can search for an optimal choice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klist = list(range(1, 20))\n",
    "scores = []\n",
    "\n",
    "for k in klist:\n",
    "    classifier = neighbors.KNeighborsClassifier(k)\n",
    "    score = model_selection.cross_val_score(classifier, X_train, y_train, cv=4)\n",
    "    scores.append(np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(klist, scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat with the best value of k from the training set\n",
    "classifier = neighbors.KNeighborsClassifier(3)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_test_pred = classifier.predict(X_test)\n",
    "metrics.confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use SVM classifer --- next class is devoted to SVM\n",
    "classifier = svm.SVC(gamma=\"auto\")\n",
    "classifier.fit(X_train, y_train)\n",
    "y_test_pred = classifier.predict(X_test)\n",
    "metrics.confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Random Forest classifer\n",
    "classifier = ensemble.RandomForestClassifier(n_estimators=100)  # set `random_state=123` to get the same random numbers\n",
    "classifier.fit(X_train, y_train)\n",
    "y_test_pred = classifier.predict(X_test)\n",
    "metrics.confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the feature importances --- we again see the petal width/height are most informative\n",
    "classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at some of the trees\n",
    "tree.plot_tree(classifier.estimators_[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.plot_tree(classifier.estimators_[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have two hyper parameters\n",
    "\n",
    "- The number of estimators\n",
    "- The maximum depth of the tree\n",
    "\n",
    "Let's use another approach to search for these best parameters: Randomized Search. It samples a fixed number of parameter settings from specified distributions. This is often more efficient than `GridSearchCV`, which exhaustively tries all combinations on a predefined grid, especially when the search space is large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.randint(7, 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# These names must match the names of the arguments\n",
    "args = {\"n_estimators\": stats.randint(50, 500), \"max_depth\": stats.randint(1, 20)}\n",
    "\n",
    "classifier = ensemble.RandomForestClassifier()  # set `random_state=123` to get the same random numbers\n",
    "\n",
    "ransearch = model_selection.RandomizedSearchCV(\n",
    "    classifier, param_distributions=args, n_iter=5, cv=4  #, random_state=123 # uncomment to get the same random numbers\n",
    ")\n",
    "\n",
    "ransearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(ransearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = ransearch.best_estimator_.predict(X_test)\n",
    "metrics.confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# For this tiny example there is no/little improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Classifier Performance vs. Training Data Size\n",
    "\n",
    "Different classifiers may perform better or worse depending on the amount of training data available. Let's systematically compare the accuracy of our chosen classifiers (Decision Tree, KNN, SVM, Random Forest) as we vary the proportion of data used for training from 10% to 90%. We'll look at the accuracy for each Iris species separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a numpy array with training size ratios, ranging from 10% to 90%\n",
    "train_size_vec = np.linspace(0.1, 0.9, 30)\n",
    "\n",
    "# create a list of classifiers\n",
    "classifiers = [\n",
    "    tree.DecisionTreeClassifier,\n",
    "    neighbors.KNeighborsClassifier,\n",
    "    svm.SVC,\n",
    "    ensemble.RandomForestClassifier,\n",
    "]\n",
    "\n",
    "# create an array that stores the diagonals of the confusion matrix as a function of training size ratio\n",
    "# and classifier\n",
    "cm_diags = np.zeros((3, len(train_size_vec), len(classifiers)), dtype=float)\n",
    "\n",
    "# loop over each training size ratio and classifier\n",
    "for n, train_size in enumerate(train_size_vec):\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "        iris.data, iris.target, train_size=train_size\n",
    "    )\n",
    "\n",
    "    for m, Classifier in enumerate(classifiers):\n",
    "        classifier = Classifier()\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_test_pred = classifier.predict(X_test)\n",
    "        cm_diags[:, n, m] = metrics.confusion_matrix(y_test, y_test_pred).diagonal()\n",
    "        cm_diags[:, n, m] /= np.bincount(y_test)\n",
    "\n",
    "# plot accuracy as a function of training size ratio\n",
    "fig, axes = plt.subplots(1, len(classifiers), figsize=(12, 3))\n",
    "\n",
    "for m, Classifier in enumerate(classifiers):\n",
    "    axes[m].plot(train_size_vec, cm_diags[2, :, m], label=iris.target_names[2])\n",
    "    axes[m].plot(train_size_vec, cm_diags[1, :, m], label=iris.target_names[1])\n",
    "    axes[m].plot(train_size_vec, cm_diags[0, :, m], label=iris.target_names[0])\n",
    "    axes[m].set_title(type(Classifier()).__name__, fontsize=\"x-small\")\n",
    "    axes[m].set_ylim(0, 1.1)\n",
    "    axes[m].set_xlim(0.1, 0.9)\n",
    "    axes[m].set_ylabel(\"classification accuracy\", fontsize=\"x-small\")\n",
    "    axes[m].set_xlabel(\"training size ratio\", fontsize=\"x-small\")\n",
    "    axes[m].legend(loc=4, fontsize=\"x-small\")\n",
    "    axes[m].tick_params(axis=\"x\", labelsize=12)\n",
    "    axes[m].tick_params(axis=\"y\", labelsize=12)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see that the error is different for each model.\n",
    "- Which classifier is best depends on the problem.\n",
    "- The good news is that it's easy to switch them in Scikit-learn.\n",
    "- Besides accuracy, computational performance can be important. For large problems with many features, a decision tree method such as Random Forest is a good one to try first.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "- Clustering can be considered as a classification problem where the classes are NOT known. For more details, see [Wikipedia](https://en.wikipedia.org/wiki/Cluster_analysis)).\n",
    "- It is an example of _unsupervised learning_ (data is unlabeled).\n",
    "- The input of a clustering algorithm contains only the feature variables and the output of the algorithm is an array of integers that represent a cluster(or class) of each sample.\n",
    "- Popular clustering methods are:\n",
    "  - [_K-means algorithm_](https://en.wikipedia.org/wiki/K-means_clustering): groups the samples into clusters such that the within-group sum of square deviation is minimized. ( `sklearn.cluster.KMeans`)\n",
    "  - [_mean-shift algorithm_](https://en.wikipedia.org/wiki/Mean_shift) : clusters the samples by fitting the data to density functions (e.g. Gaussian functions) ( `sklearn.cluster.MeanShift`)\n",
    "\n",
    "A full list of methods in Scikit-Learn [here](http://scikit-learn.org/stable/modules/clustering.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** Consider again the Iris dataset but this time we will not use the response variable. We will implement the K-means method. We need to specify the number of clusters (we will use `n_clusters = 3` since we know this in advance).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store feature data in X and response data in y\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step1: create an instance of KMeans class using number of clusters = 3\n",
    "clustering = cluster.KMeans(n_clusters=3, n_init=10, random_state=555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step2: call the fit() method\n",
    "clustering.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step3: use predict() method to make prediction\n",
    "y_pred = clustering.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the output is long, we'll look at every 8th element\n",
    "y_pred[::8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[::8]\n",
    "## NOTE: there is a good correlation btw the two, but the output has assigned different numbers to the groups\n",
    "##   than what was used in the target vector\n",
    "## - To be able to compare two arrays with metrics such as the confusion matrix, we need to rename the elements\n",
    "##      so that the same integers are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_0 = np.where(y_pred == 0)\n",
    "idx_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Clustering: Mapping Labels\n",
    "\n",
    "The K-Means algorithm assigned cluster labels (0, 1, 2) to the samples. However, these labels are arbitrary and don't necessarily match the original Iris species labels (0: setosa, 1: versicolor, 2: virginica). To evaluate the clustering using metrics like the confusion matrix against the *true* labels (`y`), we first need to find the best mapping between the predicted cluster labels (`y_pred`) and the true labels. By inspecting the results of this specific run (which depends on the `random_state`), we can determine this mapping. For example, we might find that cluster 0 corresponds mostly to species 0, cluster 1 to species 2, and cluster 2 to species 1. We'll then relabel `y_pred` accordingly for comparison. Remember, this step is only possible because we *know* the true labels in this example; in purely unsupervised clustering, we wouldn't have `y` to compare against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the elements in y_pred so that the same integers are used as in y\n",
    "idx_0, idx_1, idx_2 = (np.where(y_pred == n) for n in range(3))\n",
    "y_pred[idx_0], y_pred[idx_1], y_pred[idx_2] = 1, 0, 2\n",
    "y_pred[::8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the confusion matrix\n",
    "metrics.confusion_matrix(y, y_pred)\n",
    "\n",
    "## NOTE(numbers might be different): the algorithm was able to correctly identify all samples in group 0 (first species) as a group of its own.\n",
    "#  2 elements from group 1 was assigned to group 2\n",
    "# 14 elements from group 2 was assigned to group 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make scatter plots for each pair of features\n",
    "\n",
    "N = X.shape[1]\n",
    "\n",
    "fig, axes = plt.subplots(N, N, figsize=(12, 12), sharex=True, sharey=True)\n",
    "\n",
    "colors = [\"coral\", \"blue\", \"green\"]  # different color for each cluster\n",
    "markers = [\"^\", \"v\", \"o\"]  # different symbol for each cluster\n",
    "n_clusters = 3\n",
    "for m in range(N):\n",
    "    for n in range(N):\n",
    "        for p in range(n_clusters):\n",
    "            mask = y_pred == p\n",
    "            axes[m, n].scatter(\n",
    "                X[:, m][mask],\n",
    "                X[:, n][mask],\n",
    "                marker=markers[p],\n",
    "                s=30,\n",
    "                color=colors[p],\n",
    "                alpha=0.25,\n",
    "            )  # alpha is transparency\n",
    "\n",
    "        for idx in np.where(y != y_pred):  # Put a red rectangle at bad predictions\n",
    "            axes[m, n].scatter(\n",
    "                X[idx, m],\n",
    "                X[idx, n],\n",
    "                marker=\"s\",\n",
    "                s=30,\n",
    "                edgecolor=\"red\",\n",
    "                facecolor=(1, 1, 1, 0),\n",
    "            )\n",
    "        axes[m, n].set_xlim([0, 8])\n",
    "        axes[m, n].set_ylim([0, 8])\n",
    "        axes[m, n].set_xticks([0, 2, 4, 6, 8])\n",
    "        axes[m, n].set_yticks([0, 2, 4, 6, 8])\n",
    "\n",
    "    axes[N - 1, m].set_xlabel(iris.feature_names[m], fontsize=16)\n",
    "    axes[m, 0].set_ylabel(iris.feature_names[m], fontsize=16)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(\"clustering_iris.pdf\")\n",
    "## NOTE: the clustering does a very good job at recognizing which sample belongs to distinct group,\n",
    "## but because of the overlap in the features we cannot expect any unsupervised clustering algorithm can\n",
    "## fully resolve the various groups in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "- _Numerical Python: A Practical Techniques Approach for Industry_ by Robert Johansson (Chapter 15)\n",
    "- _Python Data Science Handbook_ by Jake VanderPlas\n",
    "- https://machinelearningmastery.com/supervised-and-unsupervised-machine-learning-algorithms/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
